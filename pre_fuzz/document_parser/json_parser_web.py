import re
import json
import os
# this is the json parser that will parse the text files and convert them to json files
# this works with text files that are generated by the pdf_scraper.py

def parse_object(text):
    lines = text.strip().split('\n')
    idx = 0
    total_lines = len(lines)
    
    # Skip empty lines at the beginning
    while idx < total_lines and lines[idx].strip() == '':
        idx += 1
    
    # Extract the object name
    object_name = lines[idx].strip()
    idx += 1
    
    # Initialize the JSON output
    json_output = {
        "object": object_name,
        "apiName": object_name,
        "apiType": "Object",
        "apiDescription": "",
        "version": "",
        "savePrefs": "",
        "security": "",
        "product": "",
    }
    
    # Skip empty lines after object name
    while idx < total_lines and lines[idx].strip() == '':
        idx += 1
    
    # Check if metadata table is present
    metadata_keys = []
    metadata_values = []
    if idx < total_lines and '|' in lines[idx]:
        # Extract metadata headers
        metadata_keys = [key.strip() for key in lines[idx].split('|')]
        idx += 1
        
        # Skip separator line (e.g., '----')
        while idx < total_lines and re.match(r'^-+\s*(\|\s*-+)*$', lines[idx]):
            idx += 1
        
        # Extract metadata values
        if idx < total_lines and '|' in lines[idx]:
            metadata_values = [value.strip() for value in lines[idx].split('|')]
            idx += 1
    
    # Map metadata keys to values
    metadata = dict(zip(
        [key.lower().replace(' ', '') for key in metadata_keys],
        metadata_values
    ))
    
    # Set metadata in json_output
    json_output['version'] = metadata.get('version', '')
    json_output['savePrefs'] = metadata.get('save-prefs', '')
    json_output['security'] = metadata.get('security', '')
    json_output['product'] = metadata.get('product', '')
    
    # Skip empty lines after metadata
    while idx < total_lines and lines[idx].strip() == '':
        idx += 1
    
    # Extract the description 
    description_lines = []
    while idx < total_lines:
        line = lines[idx].strip()
        description_lines.append(line)
        idx += 1
    description = ' '.join(description_lines)
    
    # Clean up description (remove multiple spaces)
    description = re.sub(r'\s+', ' ', description)
    json_output['apiDescription'] = description.strip()
    
    return json_output


def parse_other(content, parent_folder):
    # Extract object name from the parent folder
    object_name = os.path.basename(parent_folder)

    lines = content.strip().split("\n")
    
    # Extract the API name (first line)
    api_name = lines[0].strip().replace("¶", "")
    
    # Initialize placeholders
    api_description = ""
    examples = []
    
    # Parsing flags
    parsing_description = True
    
    for line in lines[1:]:
        line = line.strip()
        
        # Parse description (until examples or other sections are encountered)
        if parsing_description:
            api_description += " " + line
    
    # Construct the JSON object
    api_data = {
        "Object": object_name,  # Dynamically determined from parent folder
        "API_Name": api_name,
        "API_Type": "Other",
        "API_Description": api_description.strip(),
    }
    
    return api_data

def parse_property(text, parent_folder):
    lines = text.strip().split('\n')
    idx = 0
    total_lines = len(lines)
    parent_object = os.path.basename(parent_folder)
    
    # Skip empty lines at the beginning
    while idx < total_lines and lines[idx].strip() == '':
        idx += 1
    
    # Extract the property name
    property_name_line = lines[idx].strip()
    property_name = property_name_line.replace('¶', '').strip()
    idx += 1
    
    # Initialize the JSON output
    json_output = {
        "Object": parent_object,
        "API_Name": property_name,
        "API_Type": "Properties",
        "API_Description": "",
        "Version_Key": "",
        "Save_Prefs": "",
        "Security": "",
        "Product": "",
        "Type": "",
        "Access": "",
        "Examples": []
    }
    
    # Skip empty lines after property name
    while idx < total_lines and lines[idx].strip() == '':
        idx += 1
    
    # Check if metadata table is present
    metadata_keys = []
    metadata_values = []
    if idx < total_lines and '|' in lines[idx]:
        # Extract metadata headers
        metadata_keys_line = lines[idx].strip()
        metadata_keys = [key.strip() for key in metadata_keys_line.split('|')]
        idx += 1
        
        # Skip separator line (e.g., '----')
        while idx < total_lines and re.match(r'^-+\s*(\|\s*-+)*$', lines[idx]):
            idx += 1
        
        # Extract metadata values
        if idx < total_lines and '|' in lines[idx]:
            metadata_values_line = lines[idx].strip()
            metadata_values = [value.strip() for value in metadata_values_line.split('|')]
            idx += 1
        
        # Map metadata keys to values
        metadata = dict(zip(
            [key.lower().replace(' ', '_') for key in metadata_keys],
            metadata_values
        ))
        
        # Set metadata in json_output
        json_output['Version_Key'] = metadata.get('version', '')
        json_output['Save_Prefs'] = metadata.get('save-prefs', '')
        json_output['Security'] = metadata.get('security', '')
        json_output['Product'] = metadata.get('product', '')
        json_output['Type'] = metadata.get('type', '')
        json_output['Access'] = metadata.get('access', '')
    
    # If metadata table is not present, check for 'Type' and 'Access' separately
    else:
        # Check for 'Type' and 'Access' table
        if idx < total_lines and '|' in lines[idx]:
            # Extract metadata headers
            metadata_keys_line = lines[idx].strip()
            metadata_keys = [key.strip() for key in metadata_keys_line.split('|')]
            idx += 1
            
            # Skip separator line (e.g., '----')
            while idx < total_lines and re.match(r'^-+\s*(\|\s*-+)*$', lines[idx]):
                idx += 1
            
            # Extract metadata values
            if idx < total_lines and '|' in lines[idx]:
                metadata_values_line = lines[idx].strip()
                metadata_values = [value.strip() for value in metadata_values_line.split('|')]
                idx += 1
            
            # Map metadata keys to values
            metadata = dict(zip(
                [key.lower().replace(' ', '_') for key in metadata_keys],
                metadata_values
            ))
            
            # Set metadata in json_output
            json_output['Type'] = metadata.get('type', '')
            json_output['Access'] = metadata.get('access', '')
    
    # Skip empty lines after metadata
    while idx < total_lines and lines[idx].strip() == '':
        idx += 1
    
    # Extract the description
    description_lines = []
    while idx < total_lines:
        line = lines[idx].strip()
        # Check if we have reached the Examples section
        if re.match(r'^Example\s*\d*:', line):
            break
        description_lines.append(line)
        idx += 1
    description = ' '.join(description_lines)
    description = re.sub(r'\s+', ' ', description)  # Clean up extra spaces
    json_output['API_Description'] = description.strip()
    
    # Extract Examples
    examples = []
    while idx < total_lines:
        line = lines[idx].strip()
        if re.match(r'^Example\s*\d*:', line):
            # Start of a new example
            example_lines = [line]
            idx += 1
            while idx < total_lines and not re.match(r'^Example\s*\d*:', lines[idx].strip()):
                example_lines.append(lines[idx])
                idx += 1
            example_text = '\n'.join(example_lines)
            examples.append(example_text.strip())
        else:
            idx += 1
    json_output['Examples'] = examples
    
    return json_output

# def parse_parameters_table(text):
#     """Parse parameters from a table format."""
#     params = {}
#     lines = text.strip().split('\n')
#     if not lines or len(lines) < 3:
#         return params
        
#     content_lines = [line for line in lines[2:] if line.strip()]
    
#     for line in content_lines:
#         parts = line.split('|', 1)
#         if len(parts) == 2:
#             param_name = parts[0].strip()
#             description = parts[1].strip()
#             param_name = param_name.replace('(optional)', '').strip()
#             params[param_name] = {"description": description}
    
#     return params

def parse_parameters_table(text):
    """Parse parameters from a table format, with or without headers."""
    params = {}
    lines = text.strip().split('\n')
    if not lines:
        return params

    # Check if the first two lines are header and separator
    if len(lines) >= 2:
        header_line = lines[0].strip()
        separator_line = lines[1].strip()
        # Check if header contains 'Parameter' and 'Description', and separator is valid
        if ('Parameter' in header_line and 'Description' in header_line and
            re.match(r'^[-| ]+$', separator_line)):
            # Skip header and separator lines
            content_lines = lines[2:]
        else:
            # Process all lines as parameter lines
            content_lines = lines
    else:
        # Not enough lines for header/separator, process all
        content_lines = lines

    for line in content_lines:
        line = line.strip()
        if not line:
            continue
        parts = line.split('|', 1)  # Split into two parts at the first |
        if len(parts) == 2:
            param_name = parts[0].strip()
            description = parts[1].strip()
            # Remove '(optional)' from parameter name if present
            param_name = param_name.replace('(optional)', '').strip()
            # If space exists like "a string", "An array of Span objects", "object literal", change to NoParameterName
            if ' ' in param_name:
                param_name = "NoParameterName"
            params[param_name] = {"description": description}
    return params

def parse_method(text, object_folder):
    """Parse documentation text into a structured JSON format."""
    object_name = os.path.basename(object_folder)
    result = {
        "Object": object_name,
        "API_Name": "",
        "API_Type": "Method",
        "API_Description": "",
        "Version": "",
        "Save-Prefs": "",
        "Security": "",
        "Product": "",
        "Parameters": {},
        "Returns": "",
        "Examples": []
    }
    
    # Extract API name
    lines = text.split('\n')
    for line in lines:
        if line.strip() and '¶' in line:
            result["API_Name"] = line.strip('¶').strip()
            break
    
    # Parse version table
    version_match = re.search(r'Version \| Save-Prefs \| Security \| Product\n-+\n([\d.]+ \| \w+ \| \w+ \| \w+)', text)
    if version_match:
        version_info = version_match.group(1).split('|')
        result["Version"] = version_info[0].strip()
        result["Save-Prefs"] = version_info[1].strip()
        result["Security"] = version_info[2].strip()
        result["Product"] = version_info[3].strip()
    
    # Extract description - look for text between version table and first ** section
    parts = text.split('\n-----------------------------------------\n')
    if len(parts) > 1:
        description_section = parts[1].split('\n\n**')[0]
        # Skip any version information line and empty lines
        description_lines = [line for line in description_section.split('\n') if line.strip() and '|' not in line]
        if description_lines:
            result["API_Description"] = description_lines[0].strip()
    
   # Find all sections that start with **
    # Updated regex to handle single or double newlines before next section
    sections = re.finditer(
        r'\*\*(.*?)\*\*\s*(.*?)(?=(?:\nExample)|\*\*|\Z)',
        text,
        re.DOTALL
    )
    # for section in sections:
    #     section_name = section.group(1).strip()
    #     section_content = section.group(2).strip()
        
    #     if section_name == "Parameters":
    #         if 'Parameter | Description' in section_content:
    #             result["Parameters"] = parse_parameters_table(section_content)
    #         else:
    #             param_lines = section_content.split('\n')
    #             for line in param_lines:
    #                 if '*' in line:
    #                     param_parts = line.split('`')
    #                     if len(param_parts) > 1:
    #                         param_name = param_parts[1].strip('` ')
    #                         full_line = line.strip('* ')
    #                         result["Parameters"][param_name] = {"description": full_line}
    #     else:
    #         result[section_name] = section_content
    for section in sections:
        section_name = section.group(1).strip()
        section_content = section.group(2).strip()
        
        if section_name == "Parameters":
            # Attempt to parse as table first
            params = parse_parameters_table(section_content)
            if params:
                result["Parameters"] = params
            else:
                # Fallback to processing lines with *
                param_lines = section_content.split('\n')
                for line in param_lines:
                    line = line.strip()
                    if '*' in line:
                        # Extract parameter name enclosed in `backticks`
                        param_parts = re.findall(r'`([^`]+)`', line)
                        if param_parts:
                            param_name = param_parts[0]
                            description = line.replace(f'* `{param_name}`', '').strip()
                            result["Parameters"][param_name] = {"description": description}
        # elif section_name == "Returns":
        #     result["Returns"] = section_content.replace('`', '').strip()
        else:
            result[section_name] = section_content
    
    # Extract examples (including their code blocks)
    examples = []
    example_matches = re.finditer(r'Example\s*\d*:?(.*?)(?=(?:\n\nExample|\Z))', text, re.DOTALL)
    for match in example_matches:
        example_text = match.group(1).strip()
        if example_text:
            examples.append(example_text)
    
    result["Examples"] = examples
    
    return result

def read_text_file(file_path):
    with open(file_path, 'r', encoding='utf-8') as file:
        content = file.read()
    return content

def write_json_file(data, file_path):
    """Write JSON data to a file."""
    with open(file_path, 'w', encoding='utf-8') as json_file:
        json.dump(data, json_file, indent=2)

def write_json_output(data, output_file_path):
    with open(output_file_path, 'w', encoding='utf-8') as json_file:
        json.dump([data], json_file, indent=2)

def process_directory(input_directory, output_directory):
    def get_parent_folder(path):
        """Extract the parent directory name."""
        parent_path = os.path.dirname(path)
        return os.path.basename(parent_path)

    """Process the directory structure and parse files."""
    for root, dirs, files in os.walk(input_directory):
        for file_name in files:
            if file_name.endswith(".txt"):
                file_path = os.path.join(root, file_name)
                if ' ' in file_name:
                    continue

                # Determine output JSON file path based on input hierarchy
                relative_path = os.path.relpath(file_path, input_directory)
                json_file_path = os.path.join(output_directory, os.path.splitext(relative_path)[0] + ".json")

                # Create the output directory if it does not exist
                os.makedirs(os.path.dirname(json_file_path), exist_ok=True)

                # Determine file type based on its location and process accordingly
                if file_name == "object.txt":
                    # Parse object file and rename the JSON file to the object name
                    content = read_text_file(file_path)
                    parsed_data = parse_object(content)
                elif "methods" in root:
                    # Parse method file
                    object_name = os.path.basename(os.path.dirname(root))
                    content = read_text_file(file_path)
                    parsed_data = parse_method(content, object_name)
                elif "properties" in root:
                    # Parse property file
                    object_name = os.path.basename(os.path.dirname(root))
                    content = read_text_file(file_path)
                    parsed_data = parse_property(content, object_name)
                else:
                    # Parse other file
                    content = read_text_file(file_path)
                    parsed_data = parse_other(content, root)

                # Write parsed JSON
                write_json_file(parsed_data, json_file_path)
                print(f"Processed {file_path} -> {json_file_path}")

if __name__ == "__main__":
    input_directory = "./output/" 
    output_directory = "./json/"
    process_directory(input_directory, output_directory)
